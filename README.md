# x-maes
MAE 拓展
models_mae_AGAT.py
MAE+AGAT
```
@inproceedings{wu2022towards,
  title={Towards efficient adversarial training on vision transformers},
  author={Wu, Boxi and Gu, Jindong and Li, Zhifeng and Cai, Deng and He, Xiaofei and Liu, Wei},
  booktitle={European Conference on Computer Vision},
  pages={307--325},
  year={2022},
  organization={Springer}
}
```
models_mae_CAE.py
MAE+CAE
```
@article{ContextAutoencoder2022,
  title={Context Autoencoder for Self-Supervised Representation Learning},
  author={Chen, Xiaokang and Ding, Mingyu and Wang, Xiaodi and Xin, Ying and Mo, Shentong and Wang, Yunhao and Han, Shumin and Luo, Ping and Zeng, Gang and Wang, Jingdong},
  journal={arXiv preprint arXiv:2202.03026},
  year={2022}
}
```
models_mae_CodeBook.py
MAE+codebook
```
codebook
```
models_mae_DCR.py
MAE+DCR
```

```
models_mae_MoCo.py
MAE+MoCo
models_mae_NN.py
MAE+NN
models_mae_RDA.py
MAE+RDA
```
@article{xu2022masked,
  title={Masked autoencoders are robust data augmentors},
  author={Xu, Haohang and Ding, Shuangrui and Zhang, Xiaopeng and Xiong, Hongkai and Tian, Qi},
  journal={arXiv preprint arXiv:2206.04846},
  year={2022}
}
```
```
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

```
